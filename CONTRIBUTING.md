# Contributing to RAG Service ğŸ¤

RAG Serviceì— ê¸°ì—¬í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì´ ê°€ì´ë“œëŠ” ì§€ëŠ¥í˜• ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ ê°œë°œì— ì°¸ì—¬í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸ“‹ ê¸°ì—¬ ë°©ì‹

### ğŸ› ë²„ê·¸ ë¦¬í¬íŠ¸
- ê²€ìƒ‰ ì •í™•ë„ ë¬¸ì œ, ë‹µë³€ í’ˆì§ˆ ì´ìŠˆ ë“± êµ¬ì²´ì ìœ¼ë¡œ ì‹ ê³ 
- ì§ˆë¬¸ ì˜ˆì‹œ, ê¸°ëŒ€ ë‹µë³€, ì‹¤ì œ ë‹µë³€ í¬í•¨
- ì‚¬ìš©ëœ ë¬¸ì„œ ìœ í˜•, ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì •ë³´ ì œê³µ

### ğŸ’¡ ê¸°ëŠ¥ ì œì•ˆ
- ìƒˆë¡œìš´ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜, ì–¸ì–´ ëª¨ë¸ í†µí•© ì œì•ˆ
- ë‹µë³€ í’ˆì§ˆ ê°œì„ , ì¸ìš© ì •í™•ë„ í–¥ìƒ ì•„ì´ë””ì–´
- ë‹¤êµ­ì–´ ì§€ì›, ë„ë©”ì¸ íŠ¹í™” ê¸°ëŠ¥ ì œì•ˆ

### ğŸ”§ ì½”ë“œ ê¸°ì—¬
1. Fork ìƒì„±
2. Feature branch ìƒì„±: `git checkout -b feature/HybridSearchEnhancement`
3. ë³€ê²½ì‚¬í•­ ì»¤ë°‹: `git commit -m 'Improve vector search accuracy'`
4. Branchì— Push: `git push origin feature/HybridSearchEnhancement`
5. Pull Request ìƒì„±

## ğŸ›  ê°œë°œ í™˜ê²½ ì„¤ì •

### í•„ìš” ì¡°ê±´
- Python 3.11+
- MongoDB Atlas ê³„ì • (ë˜ëŠ” ë¡œì»¬ MongoDB)
- Azure OpenAI êµ¬ë…
- Docker (ì„ íƒì‚¬í•­)

### ë¡œì»¬ ì„¤ì •
```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-username/rag-service.git
cd rag-service

# ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
pip install -r requirements-dev.txt

# í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp env.example .env
# .env íŒŒì¼ì— MongoDB URI, Azure OpenAI ì¸ì¦ ì •ë³´ ì…ë ¥

# ê°œë°œ ì„œë²„ ì‹¤í–‰
uvicorn main:app --reload --port 8002
```

### ê°œë°œìš© MongoDB ì„¤ì •
```bash
# Dockerë¡œ ë¡œì»¬ MongoDB ì‹¤í–‰
docker run -d --name rag-mongodb \
  -p 27017:27017 \
  -e MONGO_INITDB_ROOT_USERNAME=admin \
  -e MONGO_INITDB_ROOT_PASSWORD=password \
  mongo:7.0

# ë˜ëŠ” MongoDB Atlas ì‚¬ìš© (ê¶Œì¥)
# https://www.mongodb.com/atlasì—ì„œ ë¬´ë£Œ í´ëŸ¬ìŠ¤í„° ìƒì„±
```

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
pytest tests/ -v
```

### ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
```bash
# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸
python tests/test_search_quality.py

# RAG íŒŒì´í”„ë¼ì¸ end-to-end í…ŒìŠ¤íŠ¸
python tests/test_rag_pipeline.py

# ë‹µë³€ í’ˆì§ˆ í‰ê°€
python tests/test_answer_quality.py
```

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```bash
# ê²€ìƒ‰ ì†ë„ ë²¤ì¹˜ë§ˆí¬
python tests/benchmark_search.py

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í”„ë¡œíŒŒì¼ë§
python -m memory_profiler tests/test_memory_usage.py

# ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
python tests/test_concurrent_requests.py
```

## ğŸ” RAG ì‹œìŠ¤í…œ ê°œë°œ ê°€ì´ë“œ

### ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”
```python
# ì¢‹ì€ ì˜ˆì‹œ: íš¨ìœ¨ì ì¸ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
async def hybrid_search(self, query: str, k: int = 6) -> List[Dict]:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í…ìŠ¤íŠ¸ + ë²¡í„°)"""
    
    # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
    text_task = self._atlas_text_search(query, k=20)
    vector_task = self._atlas_vector_search(query, k=20)
    
    text_results, vector_results = await asyncio.gather(text_task, vector_task)
    
    # RRF ìœµí•©ìœ¼ë¡œ ê²°ê³¼ ê²°í•©
    return self._rrf_fuse(text_results, vector_results, topk=k)

# ë‚˜ìœ ì˜ˆì‹œ: ìˆœì°¨ì  ê²€ìƒ‰
def sequential_search(self, query: str):
    text_results = self._text_search(query)  # ë™ê¸° ì²˜ë¦¬
    vector_results = self._vector_search(query)  # ë™ê¸° ì²˜ë¦¬
    return text_results + vector_results  # ë‹¨ìˆœ ê²°í•©
```

### í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
```python
# íš¨ê³¼ì ì¸ RAG í”„ë¡¬í”„íŠ¸ ì„¤ê³„
SYSTEM_PROMPT = """
ë„ˆëŠ” ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ì•„ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•œë‹¤.

ì§€ì¹¨:
1. ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ê°€ ìˆìœ¼ë©´ êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€
2. ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ê°€ ì—†ìœ¼ë©´ ì†”ì§íˆ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€
3. ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ì•ŠìŒ
4. ë‹µë³€ì— ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì§€ ì•ŠìŒ (ë³„ë„ ì œê³µë¨)

ë‹µë³€ í˜•ì‹:
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì„¤ëª…
- í•„ìš”ì‹œ ë²ˆí˜¸ë‚˜ ëª©ë¡ í™œìš©
- ì „ë¬¸ ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…
"""

USER_PROMPT = """
ì§ˆë¬¸: {question}

ì»¨í…ìŠ¤íŠ¸:
{context}

ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
"""
```

### ë²¡í„° ì„ë² ë”© ìµœì í™”
```python
class OptimizedEmbedding:
    def __init__(self):
        self.embedding_cache = {}
        self.batch_size = 16
    
    @lru_cache(maxsize=1000)
    def embed_text(self, text: str) -> List[float]:
        """ìºì‹œëœ ì„ë² ë”© ìƒì„±"""
        if text in self.embedding_cache:
            return self.embedding_cache[text]
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        processed_text = self._preprocess_text(text)
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± í–¥ìƒ
        embedding = self.embedding_model.embed_query(processed_text)
        
        self.embedding_cache[text] = embedding
        return embedding
    
    def _preprocess_text(self, text: str) -> str:
        """ì„ë² ë”© í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ ì „ì²˜ë¦¬"""
        # ë¶ˆí•„ìš”í•œ ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°
        # ë¬¸ì¥ ì •ê·œí™”, í‚¤ì›Œë“œ ì¶”ì¶œ ë“±
        return processed_text
```

## ğŸ“ ì½”ë”© ìŠ¤íƒ€ì¼

### RAG ê´€ë ¨ ì½”ë”© ê·œì¹™
```python
# ê²€ìƒ‰ ê²°ê³¼ íƒ€ì… íŒíŠ¸ ì‚¬ìš©
from typing import List, Dict, Optional, Tuple

SearchResult = Dict[str, Any]
DocumentChunk = Dict[str, str]
RetrievalScore = float

async def search_documents(
    query: str,
    filters: Optional[Dict[str, Any]] = None,
    max_results: int = 6
) -> List[SearchResult]:
    """ë¬¸ì„œ ê²€ìƒ‰ í•¨ìˆ˜"""
    pass

# ì„¤ì • ê°’ì€ ìƒìˆ˜ë¡œ ì •ì˜
class RAGConfig:
    DEFAULT_TOP_K = 6
    MAX_CONTEXT_LENGTH = 4000
    RRF_K_VALUE = 60
    VECTOR_SEARCH_CANDIDATES = 800
    TEXT_SEARCH_LIMIT = 20
```

### ì—ëŸ¬ í•¸ë“¤ë§
```python
class RAGException(Exception):
    """RAG ì„œë¹„ìŠ¤ ê¸°ë³¸ ì˜ˆì™¸"""
    pass

class SearchException(RAGException):
    """ê²€ìƒ‰ ê´€ë ¨ ì˜ˆì™¸"""
    pass

class GenerationException(RAGException):
    """ë‹µë³€ ìƒì„± ê´€ë ¨ ì˜ˆì™¸"""
    pass

# ì‚¬ìš© ì˜ˆì‹œ
try:
    search_results = await self.hybrid_search(query)
    if not search_results:
        raise SearchException("No relevant documents found")
    
    answer = await self.generate_answer(query, search_results)
    if not answer:
        raise GenerationException("Failed to generate answer")
        
except SearchException as e:
    logger.warning(f"Search failed: {e}")
    return {"success": False, "error": "search_failed"}
```

## ğŸ“ ì»¤ë°‹ ë©”ì‹œì§€ ê·œì¹™

### RAG ê´€ë ¨ ì»¤ë°‹ íƒ€ì…
- `feat(search)`: ê²€ìƒ‰ ê¸°ëŠ¥ ê°œì„ 
- `feat(rag)`: RAG íŒŒì´í”„ë¼ì¸ ê¸°ëŠ¥ ì¶”ê°€
- `fix(retrieval)`: ë¬¸ì„œ ê²€ìƒ‰ ë²„ê·¸ ìˆ˜ì •
- `perf(embedding)`: ì„ë² ë”© ì„±ëŠ¥ ìµœì í™”
- `docs(api)`: API ë¬¸ì„œ ì—…ë°ì´íŠ¸

### ì˜ˆì‹œ
```
feat(search): implement adaptive RRF fusion algorithm

- Add dynamic weight adjustment based on query type
- Improve retrieval accuracy by 15% on benchmark dataset
- Add comprehensive unit tests for fusion logic
- Update performance benchmarks

Fixes #87
Closes #91
```

## ğŸ— Pull Request ê°€ì´ë“œë¼ì¸

### RAG PR ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ê²€ìƒ‰ ì •í™•ë„ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë‹µë³€ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
- [ ] ë‹¤ì–‘í•œ ì§ˆë¬¸ ìœ í˜• í…ŒìŠ¤íŠ¸

### ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€
```python
# ê²€ìƒ‰ ì •í™•ë„ ì¸¡ì •
def evaluate_search_quality(test_queries: List[str]) -> Dict[str, float]:
    """ê²€ìƒ‰ í’ˆì§ˆ í‰ê°€ ë©”íŠ¸ë¦­"""
    metrics = {
        "precision_at_k": 0.0,
        "recall_at_k": 0.0, 
        "mrr": 0.0,  # Mean Reciprocal Rank
        "ndcg": 0.0  # Normalized Discounted Cumulative Gain
    }
    
    for query in test_queries:
        # ê²€ìƒ‰ ì‹¤í–‰ ë° í‰ê°€
        results = search_function(query)
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        
    return metrics
```

### ë‹µë³€ í’ˆì§ˆ í‰ê°€
- **ê´€ë ¨ì„±**: ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ì—°ê´€ì„± (1-5ì )
- **ì •í™•ì„±**: ë‹µë³€ ë‚´ìš©ì˜ ì •í™•ë„ (1-5ì )
- **ì™„ì„±ë„**: ë‹µë³€ì˜ ì™„ì „ì„± (1-5ì )
- **ëª…í™•ì„±**: ë‹µë³€ì˜ ì´í•´í•˜ê¸° ì‰¬ì›€ (1-5ì )

## ğŸ¯ ì„±ëŠ¥ ê¸°ì¤€

### ê²€ìƒ‰ ì„±ëŠ¥ ëª©í‘œ
- **ê²€ìƒ‰ ì‹œê°„**: í‰ê·  500ms ì´í•˜
- **ì •í™•ë„**: Precision@5 80% ì´ìƒ
- **ì¬í˜„ìœ¨**: Recall@10 90% ì´ìƒ
- **ë‹µë³€ í’ˆì§ˆ**: í‰ê·  4.0/5.0 ì´ìƒ

### ì‹œìŠ¤í…œ ì„±ëŠ¥ ëª©í‘œ
- **ì‘ë‹µ ì‹œê°„**: 95th percentile 8ì´ˆ ì´í•˜
- **ë™ì‹œ ì²˜ë¦¬**: 50ê°œ ìš”ì²­
- **ë©”ëª¨ë¦¬ ì‚¬ìš©**: ìš”ì²­ë‹¹ 100MB ì´í•˜
- **ê°€ìš©ì„±**: 99.5% ì´ìƒ

## ğŸ”„ ë°ì´í„° ê´€ë¦¬

### ë¬¸ì„œ ì¸ë±ì‹±
```python
# ìƒˆë¡œìš´ ë¬¸ì„œ ì¶”ê°€ ì›Œí¬í”Œë¡œìš°
async def add_documents(documents: List[Document]) -> bool:
    """ë¬¸ì„œ ì¶”ê°€ ë° ì¸ë±ì‹±"""
    
    # 1. ë¬¸ì„œ ì „ì²˜ë¦¬
    processed_docs = [preprocess_document(doc) for doc in documents]
    
    # 2. ì²­í‚¹ (ë¬¸ì„œ ë¶„í• )
    chunks = []
    for doc in processed_docs:
        doc_chunks = chunk_document(doc, chunk_size=1000, overlap=200)
        chunks.extend(doc_chunks)
    
    # 3. ì„ë² ë”© ìƒì„±
    embeddings = await generate_embeddings_batch(chunks)
    
    # 4. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    await self.collection.insert_many([
        {
            "content": chunk.content,
            "source": chunk.source,
            "page_number": chunk.page,
            "embedding": embedding,
            "metadata": chunk.metadata
        }
        for chunk, embedding in zip(chunks, embeddings)
    ])
    
    return True
```

### ì¸ë±ìŠ¤ ê´€ë¦¬
```javascript
// MongoDB Atlas Vector Search ì¸ë±ìŠ¤
{
  "type": "vectorSearch",
  "name": "vector_index",
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1536,
      "similarity": "cosine"
    },
    {
      "type": "filter",
      "path": "metadata.category"
    }
  ]
}

// Atlas Text Search ì¸ë±ìŠ¤
{
  "type": "search", 
  "name": "text_index",
  "mappings": {
    "dynamic": false,
    "fields": {
      "content": {
        "type": "string",
        "analyzer": "korean"
      }
    }
  }
}
```

## ğŸ“ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜

### RAG ê´€ë ¨ ì´ìŠˆ ë¼ë²¨
- `search-accuracy`: ê²€ìƒ‰ ì •í™•ë„ ê´€ë ¨
- `answer-quality`: ë‹µë³€ í’ˆì§ˆ ê´€ë ¨
- `performance`: ì„±ëŠ¥ ìµœì í™”
- `embedding`: ë²¡í„° ì„ë² ë”© ê´€ë ¨
- `database`: MongoDB ê´€ë ¨

### ì´ìŠˆ í…œí”Œë¦¿
```markdown
## ğŸ” RAG í’ˆì§ˆ ì´ìŠˆ
**ì§ˆë¬¸**: "êµ¬ì²´ì ì¸ ì§ˆë¬¸ ë‚´ìš©"
**ê¸°ëŒ€ ë‹µë³€**: "ì˜ˆìƒë˜ëŠ” ë‹µë³€"
**ì‹¤ì œ ë‹µë³€**: "ì‹œìŠ¤í…œì´ ìƒì„±í•œ ë‹µë³€"
**ê²€ìƒ‰ëœ ë¬¸ì„œ**: "ê´€ë ¨ ë¬¸ì„œ ì œëª©ë“¤"
**í‰ê°€ ì ìˆ˜**: ê´€ë ¨ì„±/ì •í™•ì„±/ì™„ì„±ë„/ëª…í™•ì„± (ê° 1-5ì )
**í™˜ê²½**: MongoDB ë²„ì „, Azure OpenAI ëª¨ë¸ ë“±
```

## ğŸš€ ë°°í¬ ê°€ì´ë“œ

### í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ë²¡í„° ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ
- [ ] ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ì™„ë£Œ
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë³´ì•ˆ ê²€ì‚¬ ì™„ë£Œ
- [ ] ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ

### ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```python
# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
@app.middleware("http")
async def performance_monitor(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    process_time = time.time() - start_time
    
    # ë©”íŠ¸ë¦­ ë¡œê¹…
    logger.info({
        "endpoint": request.url.path,
        "method": request.method,
        "process_time": process_time,
        "status_code": response.status_code
    })
    
    return response
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ê¸°ì—¬í•˜ì‹  ì½”ë“œëŠ” [MIT License](LICENSE)ì— ë”°ë¼ ë°°í¬ë©ë‹ˆë‹¤.

---

RAG Serviceë¥¼ ë”ìš± ì§€ëŠ¥ì ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ğŸ‰ğŸ¤–
